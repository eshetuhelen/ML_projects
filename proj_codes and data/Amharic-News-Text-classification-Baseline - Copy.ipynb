{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.utils import shuffle\n",
    "np.random.seed(42) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(r'C:\\Users\\abunie\\Desktop\\tx\\data\\Amharic News Dataset.csv')\n",
    "\n",
    "data = shuffle(data)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.dropna(subset=['article'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['link'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.category.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['word_len'] = data['article'].str.split().str.len()\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.word_len.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# character level normalization\n",
    "\n",
    "Amharic has characters wich have the same sound that can be interchangably used.\n",
    "\n",
    "for example letters 'ሃ','ኅ','ኃ','ሐ','ሓ','ኻ','ሀ' have the same sound so we change them to 'ሀ' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "#method to normalize character level missmatch such as ጸሀይ and ፀሐይ\n",
    "def normalize_char_level_missmatch(input_token):\n",
    "    rep1=re.sub('[ሃኅኃሐሓኻ]','ሀ',input_token)\n",
    "    rep2=re.sub('[ሑኁዅ]','ሁ',rep1)\n",
    "    rep3=re.sub('[ኂሒኺ]','ሂ',rep2)\n",
    "    rep4=re.sub('[ኌሔዄ]','ሄ',rep3)\n",
    "    rep5=re.sub('[ሕኅ]','ህ',rep4)\n",
    "    rep6=re.sub('[ኆሖኾ]','ሆ',rep5)\n",
    "    rep7=re.sub('[ሠ]','ሰ',rep6)\n",
    "    rep8=re.sub('[ሡ]','ሱ',rep7)\n",
    "    rep9=re.sub('[ሢ]','ሲ',rep8)\n",
    "    rep10=re.sub('[ሣ]','ሳ',rep9)\n",
    "    rep11=re.sub('[ሤ]','ሴ',rep10)\n",
    "    rep12=re.sub('[ሥ]','ስ',rep11)\n",
    "    rep13=re.sub('[ሦ]','ሶ',rep12)\n",
    "    rep14=re.sub('[ዓኣዐ]','አ',rep13)\n",
    "    rep15=re.sub('[ዑ]','ኡ',rep14)\n",
    "    rep16=re.sub('[ዒ]','ኢ',rep15)\n",
    "    rep17=re.sub('[ዔ]','ኤ',rep16)\n",
    "    rep18=re.sub('[ዕ]','እ',rep17)\n",
    "    rep19=re.sub('[ዖ]','ኦ',rep18)\n",
    "    rep20=re.sub('[ጸ]','ፀ',rep19)\n",
    "    rep21=re.sub('[ጹ]','ፁ',rep20)\n",
    "    rep22=re.sub('[ጺ]','ፂ',rep21)\n",
    "    rep23=re.sub('[ጻ]','ፃ',rep22)\n",
    "    rep24=re.sub('[ጼ]','ፄ',rep23)\n",
    "    rep25=re.sub('[ጽ]','ፅ',rep24)\n",
    "    rep26=re.sub('[ጾ]','ፆ',rep25)\n",
    "    #Normalizing words with Labialized Amharic characters such as በልቱዋል or  በልቱአል to  በልቷል  \n",
    "    rep27=re.sub('(ሉ[ዋአ])','ሏ',rep26)\n",
    "    rep28=re.sub('(ሙ[ዋአ])','ሟ',rep27)\n",
    "    rep29=re.sub('(ቱ[ዋአ])','ቷ',rep28)\n",
    "    rep30=re.sub('(ሩ[ዋአ])','ሯ',rep29)\n",
    "    rep31=re.sub('(ሱ[ዋአ])','ሷ',rep30)\n",
    "    rep32=re.sub('(ሹ[ዋአ])','ሿ',rep31)\n",
    "    rep33=re.sub('(ቁ[ዋአ])','ቋ',rep32)\n",
    "    rep34=re.sub('(ቡ[ዋአ])','ቧ',rep33)\n",
    "    rep35=re.sub('(ቹ[ዋአ])','ቿ',rep34)\n",
    "    rep36=re.sub('(ሁ[ዋአ])','ኋ',rep35)\n",
    "    rep37=re.sub('(ኑ[ዋአ])','ኗ',rep36)\n",
    "    rep38=re.sub('(ኙ[ዋአ])','ኟ',rep37)\n",
    "    rep39=re.sub('(ኩ[ዋአ])','ኳ',rep38)\n",
    "    rep40=re.sub('(ዙ[ዋአ])','ዟ',rep39)\n",
    "    rep41=re.sub('(ጉ[ዋአ])','ጓ',rep40)\n",
    "    rep42=re.sub('(ደ[ዋአ])','ዷ',rep41)\n",
    "    rep43=re.sub('(ጡ[ዋአ])','ጧ',rep42)\n",
    "    rep44=re.sub('(ጩ[ዋአ])','ጯ',rep43)\n",
    "    rep45=re.sub('(ጹ[ዋአ])','ጿ',rep44)\n",
    "    rep46=re.sub('(ፉ[ዋአ])','ፏ',rep45)\n",
    "    rep47=re.sub('[ቊ]','ቁ',rep46) #ቁ can be written as ቊ\n",
    "    rep48=re.sub('[ኵ]','ኩ',rep47) #ኩ can be also written as ኵ  \n",
    "    return rep48\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['article'] = data['article'].str.replace('[^\\w\\s]','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['article'] = data['article'].apply(lambda x: normalize_char_level_missmatch(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_data = data[['article','category']]\n",
    "n_data.head()\n",
    "\n",
    "text,label = data['article'].values,data['category'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n_data.head(5).to_csv('table.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bays - CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "matrix = CountVectorizer(analyzer='word',max_features=1000,ngram_range=(1, 3))\n",
    "X = matrix.fit_transform(text).toarray()\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_label = list(set(label))\n",
    "Y= []\n",
    "for i in label:\n",
    "    Y.append(unique_label.index(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naive Bayes \n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "classifier = GaussianNB()\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predict Class\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "# Accuracy \n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_pred, target_names=['ስፖርት', 'መዝናኛ', 'ሀገር አቀፍ ዜና', 'ቢዝነስ', 'ዓለም አቀፍ ዜና', 'ፖለቲካ', 'nan']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bays - tf -df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "matrix = TfidfVectorizer(analyzer='word',max_features=1000,ngram_range=(1, 3))\n",
    "X = matrix.fit_transform(text).toarray()\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naive Bayes \n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "classifier = GaussianNB()\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predict Class\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "# Accuracy \n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_pred, target_names=['ስፖርት', 'መዝናኛ', 'ሀገር አቀፍ ዜና', 'ቢዝነስ', 'ዓለም አቀፍ ዜና', 'ፖለቲካ', 'nan']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
